# -*- coding: utf-8 -*-
"""prototype_01.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xzXNsn-oic3ybWxZVLx_vzNW1JSS_AXv

## Acesando Drive
"""

from google.colab import drive
drive.mount('/content/gdrive')

"""## Definindo Dispositivo de Procesamento"""

import torch

# Verificando disponibilidade de placa NVIDIA
if torch.cuda.is_available():
  device = torch.device('cuda')
else:
  device = torch.device('cpu')

"""## Carregando Imagens e Tratando Imagens

Nota1: Aplicar Redução de Dimensionalidade
"""

pip install elasticdeform

import torch
import torchvision.transforms as transforms
from torchvision import datasets
import numpy as np
import elasticdeform
import cv2


def deformImage(x):
    # Aplica a deformação elástica
    x_deformed = elasticdeform.deform_random_grid(x, sigma=2.15, points=30)

    # Converte para RGB
    final_image = cv2.cvtColor(x_deformed, cv2.COLOR_GRAY2RGB)

    # Genearte noise with same shape as that of the image
    noise = np.random.normal(0, 50, (final_image.shape[0], final_image.shape[1], 3))

    # Add the noise to the image
    img_noised = final_image + noise

    # Clip the pixel values to be between 0 and 255.
    img_noised = np.clip(img_noised, 0, 255).astype(np.uint8)

    return img_noised


# Definindo as transformações que você deseja aplicar às imagens
data_transforms = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.Grayscale(), # Converte as imagens para escala de cinza
    # transforms.Lambda(lambda x: np.clip(cv2.cvtColor(np.array(x), cv2.COLOR_GRAY2RGB) + np.random.normal(0, 50, (np.array(x).shape[0], np.array(x).shape[1], 3)), 0, 255).astype(np.uint8)), # Converte as imagens para RGB
    transforms.Lambda(lambda x: deformImage(np.array(x))),
    # transforms.CenterCrop(224), # Usar fotos reais, quando não for simulação
    transforms.ToTensor()
])

# Carregando as imagens do Google Drive
image_datasets = datasets.ImageFolder('/content/gdrive/My Drive/Banco_de_Dados/banco_de_dados_ResNet50', transform=data_transforms)

"""## Adicionando Classe desconhecido para imagens fora do escopo"""

# Adicionando uma categoria "desconhecido" ao conjunto de dados
if 'desconhecido' not in image_datasets.classes:
    image_datasets.classes = image_datasets.classes + ['desconhecido']

"""## Venrificando se há erro nas classes"""

print(image_datasets.classes)

"""## Separando Imagens de Treino e Teste"""

import torch
from torch.utils.data import random_split

# Definindo a proporção de dados para treinamento e teste
train_size = int(0.7 * len(image_datasets))
test_size = len(image_datasets) - train_size

# Dividindo os dados em conjuntos de treinamento e teste
train_dataset, test_dataset = random_split(image_datasets, [train_size, test_size])

# Definindo os dataloaders
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)  # Ver isso para fazer deploy

"""## Modelo pretreinado

ResNet50 + SSD300

Nota: Dois modelos ao mesmo tempo? duplicar entradas? separar modelos? model1 e model2? dois treinamentos?

- SSD300 já vem com ResNet300 no pytorch, mudar tamanho para 300X300 https://pytorch.org/hub/nvidia_deeplearningexamples_ssd/

- SSD300+ResNet50: https://debuggercafe.com/object-detection-using-ssd300-resnet50-and-pytorch/

- Pronto: ssd300_vgg16

- YOLO?

- Outros Modelos: https://pytorch.org/vision/stable/models.html#classification

- Revisar essa parte!!!
"""

import torchvision.models as models

# Carrega modelo pre-treinado
model = models.resnet50(pretrained=True)
model.eval()
model.to(device)

num_classes = 5
"""
as classes são:
                  DefeitoLeve,
                  DefeitoModerado,
                  DefeitoSevero,
                  semDefeito,
                  Desconhecido
"""

# Carregando a CNN pré-treinada
for param in model.parameters():
  param.requires_grad = False  # Desativa a propagação de gradientes para todos os parâmetros do modelo, tentar remover isso depois

model.fc = torch.nn.Sequential(torch.nn.Linear(model.fc.in_features, num_classes))  # Substituindo Ultima camada

# Modifica a camada final para ter 5 unidades de saída
# model.fc = torch.nn.Linear(model.fc.in_features, num_classes)

"""## Otimizador

Opções
- Adam: Adaptive Moment Estimation
- SGD: Stochastic Gradient Descent
- Nadam: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8321140/
- Nadam: https://pytorch.org/docs/stable/generated/torch.optim.NAdam.html
- Procurar por mais parametros
"""

import torch.optim as optim
import torch.nn as nn

# Definindo a função de perda
criterion = nn.CrossEntropyLoss()

# Definindo o otimizador
optimizer = optim.NAdam(model.parameters(), lr=0.001)
# optimizer = optim.Adam(model.parameters(), lr=0.001)

"""## Treinamento

Nota1: Dar um jeito de pegar o titulo de cada imagem

Nota2: Ver código anterior para pegar mais informações
"""

!pip install cleanlab

import pandas as pd
from cleanlab.outlier import OutOfDistribution
import time

init_time = time.time()

# Cria um objeto OutOfDistribution
ood = OutOfDistribution()

accuracy_list1 = []
loss_list = []
train_features = []

epochs = 100 # Valor entre 10-100, tentar aumentar depois, valor ideal = 25-30
for epoch in range(epochs):
    correct_train = 0
    total_train = 0
    for inputs, labels in train_loader:
        optimizer.zero_grad() # zera gradiente do otimizador
        outputs = model(inputs) # Gerando outputs do processo
        loss = criterion(outputs, labels) # Calculo do erro (Esperado VS calculado)
        loss_list.append(loss.item())
        loss.backward() # gradientes da perda
        optimizer.step() # Atualizando os pesos para os novos gradientes calculados (pesos)
        # Adiciona as saídas à lista de características de treinamento
        train_features.extend(outputs.detach().numpy())

        _, predicted = torch.max(outputs.data, 1) # Extraindo a classse, duas probabilidades, a com maior probabilidade é a classe
        total_train += labels.size(0)
        correct_train += (predicted == labels).sum().item()
    print(f'Faltam {epochs - epoch} operações para terninar o treinamento.')

    accuracy = 100 * correct_train / total_train
    accuracy_list1.append(accuracy)

print("\n\n")
print("ACURÁCIA pre-teste")
df_ac = pd.DataFrame({
    'Acurácia': accuracy_list1
})
print(df_ac)

# Treina o objeto OutOfDistribution nos dados de treinamento
train_features = np.array(train_features)
ood.fit_score(features=train_features)

final_time = time.time()

exec_time = final_time - init_time

"""## Avaliação do Modelo

Nota1: Ver código anterior para pegar mais informações

Nota2: Validação Cruzada
"""

import torch
import seaborn as sns
import numpy as np
import pandas as pd
from matplotlib import pyplot as plt

# Acuracia
correct = 0
total = 0
with torch.no_grad(): # Desativando o calculo de gradientes para o teste de desepenho
    accuracy_list = []
    accuracy_list = accuracy_list1
    for data in test_loader:
        images, labels = data
        outputs = model(images)
        _, predicted = torch.max(outputs.data, 1) # Classe prevista
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

        accuracy = 100 * correct / total
        accuracy_list.append(accuracy)

"""## Precisão e custo

Nota1: Ajustar o intervalo de épocas nos gráficos (no caso deveria ser 30)
"""

print(len(loss_list))
print(len(accuracy_list))
print(loss_list)

print(f'Acuracia: {100 * correct / total}%\n')

paleta = sns.color_palette("crest", as_cmap=True)

# Grafico de acurácia
values = np.linspace(0, 100, len(accuracy_list)) # Cria um array de valores para o gradiente
plt.figure(figsize=(15, 6))
sns.scatterplot(x=range(len(accuracy_list)), y=accuracy_list, c=accuracy_list)  # hue=accuracy_list, palette=paleta
plt.title('Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.show()

print(f'\nModel Loss: {(loss_list[-1])}\n')

# Grafico de perdas
values = np.linspace(0, len(loss_list), len(loss_list)) # Cria um array de valores para o gradiente
plt.figure(figsize=(15, 6))
sns.scatterplot(x=range(len(loss_list)), y=loss_list, c=loss_list)  # tentar mudar hue=values para c=accuracy_list
plt.title('Model Loss')
plt.xlabel('Iteration')
plt.ylabel('Loss')
plt.show()

print("\nACURÁCIA")
df_ac = pd.DataFrame({
    'Acurácia': accuracy_list
})
print(df_ac)
print("\n\n")
print("PERDAS")
df_loss = pd.DataFrame({
    'Perda': loss_list
})
print(df_loss, '\n')

"""## Testes"""

import torchvision.utils as vutils
import matplotlib.pyplot as plt
import pandas as pd

# Dados de Teste
images, labels = next(iter(test_loader))
outputs = model(images)
_, predicted = torch.max(outputs.data, 1)

# Desnormalizando as imagens
images = images / 2 + 0.5

# Normalizando as imagens para o intervalo [0, 1]
images = (images - images.min()) / (images.max() - images.min())

# Criando uma grade de imagens
grid = vutils.make_grid(images, nrow=8)

# Mostrando a grade
plt.imshow(grid.numpy().transpose((1, 2, 0)))
plt.show()

# Imprimindo os rótulos reais e previstos
classes = image_datasets.classes

print('\n\n')
# Tabelas
real = [classes[labels[i]] for i in range(len(labels))]
predito = [classes[predicted[i]] for i in range(len(predicted))]
print("TODOS")

# Cria um dicionário com os dados da tabela
df_all = pd.DataFrame({
    'Real labels': real,
    'Predicted': predito
})

# Imprime o DataFrame
print(df_all)
print('\n\n')

print("INCORRETOS")
# Cria um dicionário com os dados da
inc_real = []
inc_pred = []
img_num = []
for i in range(0, len(real)):
    if real[i] != predito[i]:
        inc_real.append(real[i])
        inc_pred.append(predito[i])
        img_num.append(i)

df_inc = pd.DataFrame({
    'Real labels': inc_real,
    'Predicted': inc_pred,
    'Imagem ID': img_num
})

# Imprime o DataFrame
print(df_inc, '\n')

loss = (len(df_inc)/len(df_all))*100
ratio = 100 - loss

print(
    f'DESEMPENHO NO DATASET DE TESTE\n'
    f'Épocas: {epochs}\n'
    )
print(
    f'Total de amostras de teste: {len(df_all)}\n'
    f'Total de predições incorretas: {len(df_inc)}\n\n'
    f'TAXA DE PRECISÃO DO TESTE: {ratio}%\n'
    f'ERRO: {loss}%'
)

"""## Salvando Modelo"""

import datetime

DATE = datetime.date.today()
VERSAO = 1
torch.save(model.state_dict(), f'/content/gdrive/My Drive/Modelos_IA/ResNet50/ResNet50-{DATE}-v{VERSAO}.pth')
with open(f'/content/gdrive/My Drive/Modelos_IA/ResNet50/ResNet50-{DATE}-v{VERSAO}.txt', 'w') as file:
    file.write(f"""
Epocas: {epochs}
Acuaracia: {accuracy_list[-1]}
Perda: {loss_list[-1]}
Classes: {classes}
Tempo de Treinamento do Modelo em Segundos: {exec_time}
            """)

"""## Train_features

Rode caso queira fazer uma validação sem precisar rodar o trainamento
"""

from cleanlab.outlier import OutOfDistribution

# Cria um objeto OutOfDistribution
ood = OutOfDistribution()

# Coleta os tensors das imagens
image_tensors = []
for imgs, _ in image_datasets:
    image_tensors.append(imgs)

# Converte a lista de tensors em um array numpy
image_array = torch.stack(image_tensors)

with torch.no_grad():
    train_features = model(image_array).detach().numpy()

# Treina o objeto OutOfDistribution nos dados de treinamento
ood.fit_score(features=train_features)

"""## Validação Local
Nota1: Ver código anterior para pegar mais informações

- outlier detection: https://docs.cleanlab.ai/stable/tutorials/outliers.html

"""

from PIL import Image
import torch
import torchvision.transforms as transforms
from matplotlib import pyplot as plt
import cv2
import numpy as np
import torchvision.models as models
import torch.nn.functional as F
from cleanlab.outlier import OutOfDistribution
from sklearn.metrics import roc_auc_score
from sklearn.linear_model import LogisticRegression

# Carrega modelo treinado
model = models.resnet50(pretrained=False)
# Modifica a camada final para ter 5 unidades de saída
num_classes = 5
# model.fc = torch.nn.Linear(model.fc.in_features, num_classes)
model.fc = torch.nn.Sequential(torch.nn.Linear(model.fc.in_features, num_classes))

# Carrega o estado do modelo
state_dict = torch.load('/content/gdrive/MyDrive/Modelos_IA/ResNet50/ResNet50-2024-02-02-v1.pth')

# Remove o prefixo "fc.0." das chaves
# state_dict = {k.replace('fc.0.', 'fc.'): v for k, v in state_dict.items()}

# Carrega o estado do modelo no modelo
model.load_state_dict(state_dict)  # Verificar depois, tentar carregar só o modelo

model.eval()

print('#'*50)
print('#'*50)
print('#'*50)
# Define as transformações de pré-processamento
preprocess = transforms.Compose([
    transforms.Resize((256, 256)),
    transforms.CenterCrop(224),
    transforms.Grayscale(),
    transforms.Lambda(lambda x: cv2.cvtColor(np.array(x), cv2.COLOR_GRAY2RGB)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

path = '/content/gdrive/MyDrive/Banco_de_Dados/Validation/realTest.png'

# Carrega a imagem e converte para RGB
image = Image.open(path)  #.convert('RGB')

# Aplica as transformações de pré-processamento
image = preprocess(image) # Normalizando a imagem

# Adiciona uma dimensão extra para o tamanho do lote
image = image.unsqueeze(0)

# Passa a imagem para o modelo
outputs = model(image)

# Obtém a previsão

# Classifica a nova imagem
img_feature = outputs.detach().numpy()

# Usa o objeto OutOfDistribution para obter pontuações de outlier para suas imagens
ood_score = ood.score(features=img_feature)

# Usa softmax para converter as saídas em probabilidades
output = F.softmax(outputs, dim=1)

# Verifica se a probabilidade é baixa
_, predicted = torch.max(output, 1)

# Obtém a probabilidade da classe mais provável
threshold = np.percentile(ood_score, 5)
#threshold = round(threshold, 7)
print(threshold)
print(ood_score)
if ood_score < threshold:
    label = image_datasets.classes[4]
else:
    label = image_datasets.classes[predicted]

# Obtém o rótulo da previsão
print(label)
img = cv2.imread(path, cv2.IMREAD_COLOR)
img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
plt.imshow(img)

# Imprime as probabilidades de todas as classes
for i, class_probability in enumerate(output[0]):
    print(f"Class {i}: {class_probability.item() * 100:.2f}%")

"""### Testando Ruido

- https://medium.com/@ms_somanna/guide-to-adding-noise-to-your-data-using-python-and-numpy-c8be815df524
"""

import cv2
from PIL import Image
from matplotlib import pyplot as plt
import numpy as np

# Read Image
img = cv2.imread('/content/drive/MyDrive/Banco_de_Dados/Validation/Leve/30-110-4-5-29.png', cv2.IMREAD_COLOR)
img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

# Convert the image to grayscale
img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

# Genearte noise with same shape as that of the image
noise = np.random.normal(0, 50, img_gray.shape)

# Add the noise to the image
img_noised = img_gray + noise

# Clip the pixel values to be between 0 and 255.
img_noised = np.clip(img_noised, 0, 255).astype(np.uint8)


plt.imshow(img_noised, cmap='gray')

"""## Testando deformação Elatica"""

import elasticdeform
import cv2
from matplotlib import pyplot as plt
import numpy as np

# Função de transformação personalizada
def elastic_transform(x):
    # Converte a imagem para escala de cinza
    x = cv2.cvtColor(np.array(x), cv2.COLOR_RGB2GRAY)

    # Aplica a deformação elástica
    x_deformed = elasticdeform.deform_random_grid(x, sigma=2.15, points=30)

    # Genearte noise with same shape as that of the image
    noise = np.random.normal(0, 50, x_deformed.shape)

    # Add the noise to the image
    img_noised = x_deformed + noise

    # Clip the pixel values to be between 0 and 255.
    img_noised = np.clip(img_noised, 0, 255).astype(np.uint8)

    return img_noised

path = "/content/drive/MyDrive/Banco_de_Dados/Validation/Leve/30-110-4-5-29.png"
img = cv2.imread(path, cv2.IMREAD_COLOR)
plt.imshow(elastic_transform(img), cmap='gray')

"""## Teste3"""

from PIL import Image
import torch
import torchvision.transforms as transforms
from matplotlib import pyplot as plt
import cv2
import torchvision.models as models

# Carregando o modelo ResNet50 pré-treinado
model = models.resnet50(pretrained=True)

# Modificando o último layer para ter o número correto de classes
model.fc = torch.nn.Sequential(torch.nn.Linear(model.fc.in_features, 5))

# Define as transformações de pré-processamento
preprocess = transforms.Compose([
 transforms.Resize(256),
 transforms.CenterCrop(224),
 transforms.ToTensor(),
 transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

path = '/content/gdrive/MyDrive/Banco_de_Dados/Validation/descTest.png'

# Carrega a imagem e converte para RGB
image = Image.open(path).convert('RGB')

# Aplica as transformações de pré-processamento
image = preprocess(image) # Normalizando a imagem

# Adiciona uma dimensão extra para o tamanho do lote
image = image.unsqueeze(0)

# Passa a imagem para o modelo
outputs = model(image)

# Obtém a previsão
_, predicted = torch.max(outputs, 1)

# Obtém o rótulo da previsão
label = classes[predicted]
print(label)
img = cv2.imread(path, cv2.IMREAD_COLOR)
img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
plt.imshow(img)

"""## Deploy (Não é prioridade)


Nota1: Usando FastAPI?

Nota2: Software CustomCTKinter?
"""

# Criando API do modelo
from fastapi import FastAPI
import torch

app = FastAPI()
model = model(input_size, output_size)
model.load_state_dict(torch.load('model.pth'))  # Verificar onde esta sendo salvo

@app.post('/predict')
def predict(data: list):
  # Converte os dados de entrada para um tensor PyTorch
  input_data = torch.tensor(data)
  # Fazendo uma previsão usando o modelo
  prediction = model(input_data)
  # Retorna a previsão como uma resposta JSON
  return {'prediction': prediction.tolist()}# -*- coding: utf-8 -*-
"""prototype_01.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xzXNsn-oic3ybWxZVLx_vzNW1JSS_AXv

## Acesando Drive
"""

from google.colab import drive
drive.mount('/content/gdrive')

"""## Definindo Dispositivo de Procesamento"""

import torch

print(torch.cuda.is_available())

# Verificando disponibilidade de placa NVIDIA
if torch.cuda.is_available():
  device = torch.device('cuda')
else:
  device = torch.device('cpu')

!nvidia-smi

"""## Carregando Imagens e Tratando Imagens

Nota1: Aplicar Redução de Dimensionalidade
"""

!pip install elasticdeform

import torch
import torchvision.transforms as transforms
from torchvision import datasets
import numpy as np
import elasticdeform
import cv2


def deformImage(x):
    # Aplica a deformação elástica
    x_deformed = elasticdeform.deform_random_grid(x, sigma=2.15, points=30)

    # Converte para RGB
    final_image = cv2.cvtColor(x_deformed, cv2.COLOR_GRAY2RGB)

    # Genearte noise with same shape as that of the image
    noise = np.random.normal(0, 50, (final_image.shape[0], final_image.shape[1], 3))

    # Add the noise to the image
    img_noised = final_image + noise

    # Clip the pixel values to be between 0 and 255.
    img_noised = np.clip(img_noised, 0, 255).astype(np.uint8)

    return img_noised


# Definindo as transformações que você deseja aplicar às imagens
data_transforms = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.Grayscale(), # Converte as imagens para escala de cinza
    # transforms.Lambda(lambda x: np.clip(cv2.cvtColor(np.array(x), cv2.COLOR_GRAY2RGB) + np.random.normal(0, 50, (np.array(x).shape[0], np.array(x).shape[1], 3)), 0, 255).astype(np.uint8)), # Converte as imagens para RGB
    transforms.Lambda(lambda x: deformImage(np.array(x))),
    # transforms.CenterCrop(224), # Usar fotos reais, quando não for simulação
    transforms.ToTensor()
])

# Carregando as imagens do Google Drive
image_datasets = datasets.ImageFolder('/content/gdrive/My Drive/Banco_de_Dados/banco_de_dados_ResNet50', transform=data_transforms)

"""## Adicionando Classe desconhecido para imagens fora do escopo"""

# Adicionando uma categoria "desconhecido" ao conjunto de dados
if 'desconhecido' not in image_datasets.classes:
    image_datasets.classes = image_datasets.classes + ['desconhecido']

"""## Verificando se há erro nas classes"""

print(image_datasets.classes)

"""## Separando Imagens de Treino e Teste"""

import torch
from torch.utils.data import random_split

# Definindo a proporção de dados para treinamento e teste
train_size = int(0.7 * len(image_datasets))
test_size = len(image_datasets) - train_size

# Dividindo os dados em conjuntos de treinamento e teste
train_dataset, test_dataset = random_split(image_datasets, [train_size, test_size])

# Definindo os dataloaders
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)  # Ver isso para fazer deploy

"""## Modelo pretreinado

ResNet50 + SSD300

Nota: Dois modelos ao mesmo tempo? duplicar entradas? separar modelos? model1 e model2? dois treinamentos?

- SSD300 já vem com ResNet300 no pytorch, mudar tamanho para 300X300 https://pytorch.org/hub/nvidia_deeplearningexamples_ssd/

- SSD300+ResNet50: https://debuggercafe.com/object-detection-using-ssd300-resnet50-and-pytorch/

- Pronto: ssd300_vgg16

- YOLO?

- Outros Modelos: https://pytorch.org/vision/stable/models.html#classification

- Revisar essa parte!!!
"""

import torchvision.models as models

# Carrega modelo pre-treinado
model = models.resnet50(pretrained=True)
# model.eval()
num_classes = 5
"""
as classes são:
                  defeitoLeve,
                  defeitoModerado,
                  defeitoSevero,
                  semDefeito,
                  desconhecido
"""

# Carregando a CNN pré-treinada
for param in model.parameters():
  param.requires_grad = False  # Desativa a propagação de gradientes para todos os parâmetros do modelo, tentar remover isso depois

model.fc = torch.nn.Sequential(torch.nn.Linear(model.fc.in_features, num_classes))  # Substituindo Ultima camada

# Modifica a camada final para ter 5 unidades de saída
# model.fc = torch.nn.Linear(model.fc.in_features, num_classes)

"""## Otimizador

Opções
- Adam: Adaptive Moment Estimation
- SGD: Stochastic Gradient Descent
- Nadam: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8321140/
- Nadam: https://pytorch.org/docs/stable/generated/torch.optim.NAdam.html
- Procurar por mais parametros
"""

import torch.optim as optim
import torch.nn as nn

# Definindo a função de perda
criterion = nn.CrossEntropyLoss().to(device)

# Definindo o otimizador
optimizer = optim.NAdam(model.parameters(), lr=0.001)
# optimizer = optim.Adam(model.parameters(), lr=0.001)

"""## Treinamento

Nota1: Dar um jeito de pegar o titulo de cada imagem

Nota2: Ver código anterior para pegar mais informações
"""

!pip install cleanlab

import pandas as pd
from cleanlab.outlier import OutOfDistribution
import time

epochs_list = []
time_list = []
acuracy_list_all = []
loss_list_all = []

epochs = 30 # Valor entre 10-100, tentar aumentar depois, valor ideal = 25-30

# Move o modelo para o dispositivo correto
model = model.to(device)
for epochs in range(20, 50):
    init_time = time.time()

    # Cria um objeto OutOfDistribution
    ood = OutOfDistribution()

    accuracy_list1 = []
    loss_list = []
    train_features = []

    for epoch in range(epochs):
        correct_train = 0
        total_train = 0
        for inputs, labels in train_loader:
            inputs = inputs.to(device)
            optimizer.zero_grad() # zera gradiente do otimizador
            outputs = model(inputs).to('cpu') # Gerando outputs do processo e Movendo as saídas para a CPU
            loss = criterion(outputs, labels) # Calculo do erro (Esperado VS calculado)
            loss_list.append(loss.item())
            loss.backward() # gradientes da perda
            optimizer.step() # Atualizando os pesos para os novos gradientes calculados (pesos)
            # Adiciona as saídas à lista de características de treinamento
            # train_features.extend(outputs.detach().cpu().numpy())  # mover as características para a CPU

            _, predicted = torch.max(outputs.data, 1) # Extraindo a classse, duas probabilidades, a com maior probabilidade é a classe
            total_train += labels.size(0)
            correct_train += (predicted == labels).sum().item()
        print(f'Faltam {epochs - epoch} operações para terninar o treinamento.')

        accuracy = 100 * correct_train / total_train
        accuracy_list1.append(accuracy)

    print("\n\n")
    print("ACURÁCIA pre-teste")
    df_ac = pd.DataFrame({
        'Acurácia': accuracy_list1
    })
    print(df_ac)

    # Treina o objeto OutOfDistribution nos dados de treinamento
    # train_features = np.array(train_features)
    # ood.fit_score(features=train_features)

    final_time = time.time()

    exec_time = final_time - init_time

    epochs_list.append(epochs)
    time_list.append(exec_time)
    acuracy_list_all.append(accuracy_list1[-1])
    loss_list_all.append(loss_list[-1])

import matplotlib.pyplot as plt
import pandas as pd

# Criando o gráfico
fig, ax1 = plt.subplots()

# Plotando o tempo de execução
ax1.plot(epochs_list, time_list, marker='o', color='tab:blue', label='Tempo de Execução (segundos)')
ax1.set_xlabel('Epochs')
ax1.set_ylabel('Tempo de Execução (segundos)', color='tab:blue')
ax1.tick_params(axis='y', labelcolor='tab:blue')

# Criando um segundo eixo y para a acurácia
ax2 = ax1.twinx()
ax2.plot(epochs_list, accuracy_list_all, marker='s', color='tab:red', label='Acurácia (%)')
ax2.set_ylabel('Acurácia (%)', color='tab:red')
ax2.tick_params(axis='y', labelcolor='tab:red')

# Criando um segundo eixo y para a perda
ax3 = ax1.twinx()
ax3.plot(epochs_list, loos_list_all, marker='s', color='tab:green', label='Perda (%)')
ax3.set_ylabel('Perda (%)', color='tab:green')
ax3.tick_params(axis='y', labelcolor='tab:green')

# Adicionando título e legendas
fig.suptitle('Tempo de Execução e Acurácia por Epoch')
fig.legend(loc='upper right')

plt.show()


# Criar um DataFrame com as listas
df = pd.DataFrame({
    'Epochs': epochs_list,
    'Time': time_list,
    'Accuracy': acuracy_list_all,
    'Loss': loss_list_all
})

# Salvar o DataFrame em um arquivo CSV
df.to_csv('/content/gdrive/My Drive/Modelos_IA/ResNet50/dados_treinamento.csv', index=False)

"""## Avaliação do Modelo

Nota1: Ver código anterior para pegar mais informações

Nota2: Validação Cruzada
"""

import torch
import seaborn as sns
import numpy as np
import pandas as pd
from matplotlib import pyplot as plt

# Acuracia
correct = 0
total = 0
with torch.no_grad(): # Desativando o calculo de gradientes para o teste de desepenho
    accuracy_list = []
    accuracy_list = accuracy_list1
    for data in test_loader:
        images, labels = data
        outputs = model(images.to(device)).to('cpu')
        _, predicted = torch.max(outputs.data, 1) # Classe prevista
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

        accuracy = 100 * correct / total
        accuracy_list.append(accuracy)

"""## Precisão e custo

Nota1: Ajustar o intervalo de épocas nos gráficos (no caso deveria ser 30)
"""

print(len(loss_list))
print(len(accuracy_list))
print(loss_list)

print(f'Acuracia: {100 * correct / total}%\n')

paleta = sns.color_palette("crest", as_cmap=True)

# Grafico de acurácia
values = np.linspace(0, 100, len(accuracy_list)) # Cria um array de valores para o gradiente
plt.figure(figsize=(15, 6))
sns.scatterplot(x=range(len(accuracy_list)), y=accuracy_list, c=accuracy_list)  # hue=accuracy_list, palette=paleta
plt.title('Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.show()

print(f'\nModel Loss: {(loss_list[-1])}\n')

# Grafico de perdas
values = np.linspace(0, len(loss_list), len(loss_list)) # Cria um array de valores para o gradiente
plt.figure(figsize=(15, 6))
sns.scatterplot(x=range(len(loss_list)), y=loss_list, c=loss_list)  # tentar mudar hue=values para c=accuracy_list
plt.title('Model Loss')
plt.xlabel('Iteration')
plt.ylabel('Loss')
plt.show()

print("\nACURÁCIA")
df_ac = pd.DataFrame({
    'Acurácia': accuracy_list
})
print(df_ac)
print("\n\n")
print("PERDAS")
df_loss = pd.DataFrame({
    'Perda': loss_list
})
print(df_loss, '\n')

"""## Testes"""

import torchvision.utils as vutils
from sklearn.metrics import confusion_matrix
import matplotlib.pyplot as plt
import pandas as pd

# Dados de Teste
images, labels = next(iter(test_loader))
outputs = model(images.to(device)).to('cpu')
_, predicted = torch.max(outputs.data, 1)

# Desnormalizando as imagens
images = images / 2 + 0.5

# Normalizando as imagens para o intervalo [0, 1]
images = (images - images.min()) / (images.max() - images.min())

# Criando uma grade de imagens
grid = vutils.make_grid(images, nrow=8)

# Mostrando a grade
plt.axis('off')
plt.imshow(grid.numpy().transpose((1, 2, 0)))
plt.show()

# Imprimindo os rótulos reais e previstos
classes = image_datasets.classes

print('\n\n')
# Tabelas
real = [classes[labels[i]] for i in range(len(labels))]
predito = [classes[predicted[i]] for i in range(len(predicted))]
print("TODOS")

# Cria um dicionário com os dados da tabela
df_all = pd.DataFrame({
    'Real labels': real,
    'Predicted': predito
})

# Imprime o DataFrame
print(df_all)
print('\n\n')

print("INCORRETOS")
# Cria um dicionário com os dados da
inc_real = []
inc_pred = []
img_num = []
for i in range(0, len(real)):
    if real[i] != predito[i]:
        inc_real.append(real[i])
        inc_pred.append(predito[i])
        img_num.append(i)

df_inc = pd.DataFrame({
    'Real labels': inc_real,
    'Predicted': inc_pred,
    'Imagem ID': img_num
})

# Imprime o DataFrame
print(df_inc, '\n')

loss = (len(df_inc)/len(df_all))*100
ratio = 100 - loss
epochs = 10
print(
    f'DESEMPENHO NO DATASET DE TESTE\n'
    f'Épocas: {epochs}\n'
    )
print(
    f'Total de amostras de teste: {len(df_all)}\n'
    f'Total de predições incorretas: {len(df_inc)}\n\n'
    f'TAXA DE PRECISÃO DO TESTE: {ratio}%\n'
    f'ERRO: {loss}%'
)

# Calcula a matriz de confusão
conf_matrix = confusion_matrix(real, predito)
conf_matrix_normalized = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis]

# Plota a matriz de confusão usando seaborn
plt.figure(figsize=(6, 5))
sns.heatmap(conf_matrix_normalized, annot=True, cmap="crest", fmt=".2f", xticklabels=classes[0:4], yticklabels=classes[0:4])
plt.xlabel('Rótulo Previsto')
plt.ylabel('Rótulo Verdadeiro')
plt.title('Matriz de Confusão Normalizada')
plt.show()

"""## Salvando Modelo"""

import datetime
import os

# ----------------------------------------
DATE = datetime.date.today()
VERSAO = 1
# ----------------------------------------

# Define o caminho do diretório onde deseja salvar os arquivos
directory = f'/content/gdrive/My Drive/Modelos_IA/ResNet50/ResNet50-{DATE}'

# Verifica se o diretório existe
if not os.path.exists(directory):
    # Cria o diretório se não existir
    os.makedirs(directory)

torch.save(model.state_dict(), f'/content/gdrive/My Drive/Modelos_IA/ResNet50/ResNet50-{DATE}/ResNet50-{DATE}-v{VERSAO}.pth')
with open(f'/content/gdrive/My Drive/Modelos_IA/ResNet50/ResNet50-{DATE}/ResNet50-{DATE}-v{VERSAO}.txt', 'w') as file:
    file.write(f"""
Epocas: {epochs}
Acuaracia: {accuracy_list[-1]}
Perda: {loss_list[-1]}
Classes: {classes}
Tempo de Treinamento do Modelo em Segundos: {exec_time}
            """)

"""## Train_features

Rode caso queira fazer uma validação sem precisar rodar o trainamento
"""

from cleanlab.outlier import OutOfDistribution

# Cria um objeto OutOfDistribution
ood = OutOfDistribution()

# Coleta os tensors das imagens
image_tensors = []
for imgs, _ in image_datasets:
    image_tensors.append(imgs)

# Converte a lista de tensors em um array numpy
image_array = torch.stack(image_tensors)

with torch.no_grad():
    train_features = model(image_array).detach().numpy()

# Treina o objeto OutOfDistribution nos dados de treinamento
ood.fit_score(features=train_features)

"""## Validação Local
Nota1: Ver código anterior para pegar mais informações

- outlier detection: https://docs.cleanlab.ai/stable/tutorials/outliers.html

"""

from PIL import Image
import torch
import torchvision.transforms as transforms
from matplotlib import pyplot as plt
import cv2
import numpy as np
import torchvision.models as models
import torch.nn.functional as F
from cleanlab.outlier import OutOfDistribution
from sklearn.metrics import roc_auc_score
from sklearn.linear_model import LogisticRegression

# Carrega modelo treinado
model = models.resnet50(pretrained=False)
# Modifica a camada final para ter 5 unidades de saída
num_classes = 5
# model.fc = torch.nn.Linear(model.fc.in_features, num_classes)
model.fc = torch.nn.Sequential(torch.nn.Linear(model.fc.in_features, num_classes))

# Carrega o estado do modelo
DATE = '2024-02-09'
VER
state_dict = torch.load(f'/content/gdrive/MyDrive/Modelos_IA/ResNet50/ResNet50-{DATE}/ResNet50-{DATE}-v{VERSAO}.pth')

# Remove o prefixo "fc.0." das chaves
# state_dict = {k.replace('fc.0.', 'fc.'): v for k, v in state_dict.items()}

# Carrega o estado do modelo no modelo
model.load_state_dict(state_dict)  # Verificar depois, tentar carregar só o modelo

model.eval()

print('#'*50)
print('#'*50)
print('#'*50)
# Define as transformações de pré-processamento
preprocess = transforms.Compose([
    transforms.Resize((256, 256)),
    transforms.CenterCrop(224),
    transforms.Grayscale(),
    transforms.Lambda(lambda x: cv2.cvtColor(np.array(x), cv2.COLOR_GRAY2RGB)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

path = '/content/gdrive/MyDrive/Banco_de_Dados/Validation/realTest.png'

# Carrega a imagem e converte para RGB
image = Image.open(path)  #.convert('RGB')

# Aplica as transformações de pré-processamento
image = preprocess(image) # Normalizando a imagem

# Adiciona uma dimensão extra para o tamanho do lote
image = image.unsqueeze(0)

# Passa a imagem para o modelo
outputs = model(image)

# Obtém a previsão

# Classifica a nova imagem
img_feature = outputs.detach().numpy()

# Usa o objeto OutOfDistribution para obter pontuações de outlier para suas imagens
ood_score = ood.score(features=img_feature)

# Usa softmax para converter as saídas em probabilidades
output = F.softmax(outputs, dim=1)

# Verifica se a probabilidade é baixa
_, predicted = torch.max(output, 1)

# Obtém a probabilidade da classe mais provável
threshold = np.percentile(ood_score, 5)
#threshold = round(threshold, 7)
print(threshold)
print(ood_score)
if ood_score < threshold:
    label = image_datasets.classes[4]
else:
    label = image_datasets.classes[predicted]

# Obtém o rótulo da previsão
print(label)
img = cv2.imread(path, cv2.IMREAD_COLOR)
img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
fig = plt.gcf()
fig.set_size_inches(5,5)
plt.axis('off')
plt.imshow(img)
plt.show()

# Imprime as probabilidades de todas as classes
for i, class_probability in enumerate(output[0]):
    print(f"Class {i}: {class_probability.item() * 100:.2f}%")

"""### Testando Ruido

- https://medium.com/@ms_somanna/guide-to-adding-noise-to-your-data-using-python-and-numpy-c8be815df524
"""

import cv2
from PIL import Image
from matplotlib import pyplot as plt
import numpy as np

# Read Image
img = cv2.imread('/content/drive/MyDrive/Banco_de_Dados/Validation/Leve/30-110-4-5-29.png', cv2.IMREAD_COLOR)
img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

# Convert the image to grayscale
img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

# Genearte noise with same shape as that of the image
noise = np.random.normal(0, 50, img_gray.shape)

# Add the noise to the image
img_noised = img_gray + noise

# Clip the pixel values to be between 0 and 255.
img_noised = np.clip(img_noised, 0, 255).astype(np.uint8)


plt.imshow(img_noised, cmap='gray')

"""## Testando deformação Elatica"""

import elasticdeform
import cv2
from matplotlib import pyplot as plt
import numpy as np

# Função de transformação personalizada
def elastic_transform(x):
    # Converte a imagem para escala de cinza
    x = cv2.cvtColor(np.array(x), cv2.COLOR_RGB2GRAY)

    # Aplica a deformação elástica
    x_deformed = elasticdeform.deform_random_grid(x, sigma=2.15, points=30)

    # Genearte noise with same shape as that of the image
    noise = np.random.normal(0, 50, x_deformed.shape)

    # Add the noise to the image
    img_noised = x_deformed + noise

    # Clip the pixel values to be between 0 and 255.
    img_noised = np.clip(img_noised, 0, 255).astype(np.uint8)

    return img_noised

path = "/content/drive/MyDrive/Banco_de_Dados/Validation/Leve/30-110-4-5-29.png"
img = cv2.imread(path, cv2.IMREAD_COLOR)
# Cria uma figura com um layout de 1 linha e 2 colunas
fig, axs = plt.subplots(1, 2, figsize=(10, 5))

# Exibe a primeira imagem na primeira coluna
axs[0].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB), cmap='gray')
axs[0].set_title("Imagem Original")

# Exibe a segunda imagem na segunda coluna
axs[1].imshow(elastic_transform(img), cmap='gray')
axs[1].set_title("Imagem Transformada")

# Adiciona espaçamento entre os subplots
plt.subplots_adjust(wspace=0.5)

# Mostra o gráfico
plt.show()

"""## Teste3"""

from PIL import Image
import torch
import torchvision.transforms as transforms
from matplotlib import pyplot as plt
import cv2
import torchvision.models as models

# Carregando o modelo ResNet50 pré-treinado
model = models.resnet50(pretrained=True)

# Modificando o último layer para ter o número correto de classes
model.fc = torch.nn.Sequential(torch.nn.Linear(model.fc.in_features, 5))

# Define as transformações de pré-processamento
preprocess = transforms.Compose([
 transforms.Resize(256),
 transforms.CenterCrop(224),
 transforms.ToTensor(),
 transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

path = '/content/gdrive/MyDrive/Banco_de_Dados/Validation/descTest.png'

# Carrega a imagem e converte para RGB
image = Image.open(path).convert('RGB')

# Aplica as transformações de pré-processamento
image = preprocess(image) # Normalizando a imagem

# Adiciona uma dimensão extra para o tamanho do lote
image = image.unsqueeze(0)

# Passa a imagem para o modelo
outputs = model(image)

# Obtém a previsão
_, predicted = torch.max(outputs, 1)

# Obtém o rótulo da previsão
label = classes[predicted]
print(label)
img = cv2.imread(path, cv2.IMREAD_COLOR)
img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
plt.imshow(img)

"""## Deploy (Não é prioridade)


Nota1: Usando FastAPI?

Nota2: Software CustomCTKinter?
"""

# Criando API do modelo
from fastapi import FastAPI
import torch

app = FastAPI()
model = model(input_size, output_size)
model.load_state_dict(torch.load('model.pth'))  # Verificar onde esta sendo salvo

@app.post('/predict')
def predict(data: list):
  # Converte os dados de entrada para um tensor PyTorch
  input_data = torch.tensor(data)
  # Fazendo uma previsão usando o modelo
  prediction = model(input_data)
  # Retorna a previsão como uma resposta JSON
  return {'prediction': prediction.tolist()}